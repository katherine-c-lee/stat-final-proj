interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = school_train1)
opt_num_trees = gbm.perf(gbm_fit)
opt_num_trees
ntrees = 500
tibble(Iteration = 1:ntrees, CV = gbm_fit$cv.error) %>%
ggplot(aes(x = Iteration, y = CV)) + geom_line() +
theme_bw()
set.seed(1)
gbm_fit_slow = gbm(crimes_per1000_sqrt ~ .,
distribution = "gaussian",
n.trees = 500,
interaction.depth = 1,
shrinkage = 0.01,
cv.folds = 5,
data = school_train1)
gbm.perf(gbm_fit_slow)
# tuning interaction depth
set.seed(1)
gbm_fit_1 = gbm(crimes_per1000_sqrt ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 1,
shrinkage = 0.1,
cv.folds = 5,
data = school_train1)
gbm_fit_2 = gbm(crimes_per1000_sqrt ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 2,
shrinkage = 0.1,
cv.folds = 5,
data = school_train1)
gbm_fit_3 = gbm(crimes_per1000_sqrt ~ .,
distribution = "gaussian",
n.trees = 1000,
interaction.depth = 3,
shrinkage = 0.1,
cv.folds = 5,
data = school_train1)
ntrees = 1000
cv_errors = bind_rows(
tibble(ntree = 1:ntrees, cv_err = gbm_fit_1$cv.error, depth = 1),
tibble(ntree = 1:ntrees, cv_err = gbm_fit_2$cv.error, depth = 2),
tibble(ntree = 1:ntrees, cv_err = gbm_fit_3$cv.error, depth = 3)
)
cv_errors
interaction_depth_tuning <- cv_errors %>%
ggplot(aes(x = ntree, y = cv_err, colour = factor(depth))) +
geom_line() +
theme_bw() +
geom_hline(yintercept = min(gbm_fit_1$cv.error), color = "red",
linetype = "dashed") +
geom_vline(xintercept = which.min(gbm_fit_1$cv.error), linetype = "dotted",
color = "red") +
geom_hline(yintercept = min(gbm_fit_2$cv.error), color = "green",
linetype = "dashed") +
geom_vline(xintercept = which.min(gbm_fit_2$cv.error), linetype = "dotted",
color = "green") +
geom_hline(yintercept = min(gbm_fit_3$cv.error), color = "blue",
linetype = "dashed") +
geom_vline(xintercept = which.min(gbm_fit_3$cv.error), linetype = "dotted",
color = "blue") +
labs(x = "Number of Trees", y = "CV Error")
ggsave(filename = "results/interaction_depth_tuning.png",
plot = interaction_depth_tuning,
device = "png",
width = 6,
height = 4)
optimal_trees = which.min(gbm_fit_3$cv.error)
optimal_trees
gbm_fit_tuned = gbm_fit_3
save(gbm_fit_tuned, file = "results/gbm_fit_tuned.Rda")
# boosting model interpretation
optimal_num_trees = gbm.perf(gbm_fit_3, plot.it = FALSE)
summary(gbm_fit_tuned,
n.trees = optimal_num_trees,
plotit = FALSE) %>%
as_tibble() %>%
head(10) %>%
rename("Variable" = var, "Relative Influence" = rel.inf) %>%
write_tsv("results/top-10-features-boosting.tsv")
# partial dependence plots
plot(gbm_fit_tuned, i.var = "avg_suspensions", n.trees = optimal_num_trees)
plot(gbm_fit_tuned, i.var = "threats_no_weapon_incidents",
n.trees = optimal_num_trees)
plot(gbm_fit_tuned, i.var = "salaries_teachers", n.trees = optimal_num_trees)
printcp(tree_fit)
cp_table = printcp(tree_fit) %>% as_tibble()
tree_fit$variable.importance
treenodes_cv_error
rpart.plot(optimal_tree)
rpart.plot(optimal_tree)
printcp(tree_fit)
cp_table
treenodes_cv_error
tree_fit$variable.importance
plot(rf_fit)
p2
plot(rf_fit)
plot(rf_fit_tuned)
rf_fit_tuned$importance %>%
head()
varImpPlot(rf_fit_tuned, n.var = 10)
opt_num_trees = gbm.perf(gbm_fit)
opt_num_trees
gbm.perf(gbm_fit_slow)
interaction_depth_tuning
plot(gbm_fit_tuned, i.var = "avg_suspensions", n.trees = optimal_num_trees)
plot(gbm_fit_tuned, i.var = "threats_no_weapon_incidents",
plot(gbm_fit_tuned, i.var = "threats_no_weapon_incidents",
n.trees = optimal_num_trees)
2+2
2+2
plot(gbm_fit_tuned, i.var = "threats_no_weapon_incidents",
n.trees = optimal_num_trees)
plot(gbm_fit_tuned, i.var = "salaries_teachers", n.trees = optimal_num_trees)
plot(gbm_fit_1, i.var = "avg_suspensions", n.trees = optimal_num_trees)
plot(gbm_fit_1, i.var = "threats_no_weapon_incidents",
n.trees = optimal_num_trees)
plot(gbm_fit_1, i.var = "salaries_teachers", n.trees = optimal_num_trees)
plot(gbm_fit_1, i.var = "avg_suspensions", n.trees = optimal_num_trees)
plot(gbm_fit_tuned, i.var = "avg_suspensions", n.trees = optimal_num_trees)
plot(gbm_fit_tuned, i.var = "threats_no_weapon_incidents",
n.trees = optimal_num_trees)
plot(gbm_fit_tuned, i.var = "salaries_teachers", n.trees = optimal_num_trees)
# load libraries
library(glmnetUtils)
library(tidyverse)
# load test data
school_test = read_tsv("data/clean/school_test.tsv") %>%
mutate(across(c("urban_centric_locale", "school_type", "charter"),
factor)) %>%
select(-c(ncessch, year, county_code)) %>%
filter(crimes_per1000 < max(crimes_per1000)) %>%
mutate(crimes_per1000_sqrt = sqrt(crimes_per1000)) %>%
select(-c(crimes_per1000))
# load all models
load("results/ridge_fit.Rda")
load("results/lasso_fit.Rda")
load("results/elnet_fit.Rda")
load("results/optimal_tree.Rda")
load("results/rf_fit_tuned.Rda")
load("results/gbm_fit_tuned.Rda")
########################### Regression-Based Methods ###########################
# for benchmark, find RMSE when just predicting the mean of the training set
simple_pred = mean(school_train$crimes_per1000_sqrt)
simple_rmse_sqrt = sqrt(
mean((simple_pred-(school_test$crimes_per1000_sqrt))^2))
simple_rmse = sqrt(
mean((simple_pred^2-(school_test$crimes_per1000_sqrt)^2)^2))
lm_RMSE_sqrt = sqrt(
mean((lm_predictions-(school_test$crimes_per1000_sqrt))^2))
lm_RMSE = sqrt(
mean((lm_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate OLS RMSE
lm_predictions = predict(lm_fit, newdata = school_test)
lm_RMSE_sqrt = sqrt(
mean((lm_predictions-(school_test$crimes_per1000_sqrt))^2))
lm_RMSE = sqrt(
mean((lm_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate ridge RMSE
ridge_predictions = predict(ridge_fit,
newdata = school_test,
s = "lambda.1se") %>% as.numeric()
ridge_pred_train = predict(ridge_fit,
newdata = school_train,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(
mean((ridge_predictions-(school_test$crimes_per1000_sqrt))^2))
ridge_RMSE_fix = sqrt(
mean((ridge_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
school_train %>%
ggplot(aes(x = crimes_per1000_sqrt, y = ridge_pred_train)) +
geom_point() +
geom_abline(slope = 1)
# evaluate lasso RMSE
lasso_predictions = predict(lasso_fit,
newdata = school_test,
s = "lambda.1se") %>% as.numeric()
lasso_RMSE = sqrt(
mean((lasso_predictions-(school_test$crimes_per1000_sqrt))^2))
lasso_RMSE_fix = sqrt(
mean((lasso_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate elnet RMSE
#elnet_predictions = predict(elnet_fit,
#alpha = extract_best_elnet(elnet_fit)$alpha,
#newdata = school_test,
#s = "lambda.1se") %>% as.numeric()
#elnet_rmse = sqrt(mean((elnet_predictions - school_test$crimes_per1000_sqrt)^2))
#elnet_rmse_fix = sqrt(
#mean((elnet_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# Summary of regression methods
tibble(Method = c("OLS", "Intercept-Only", "Ridge", "Lasso"),
`Test RMSE (Sqrt Transformed)` =
c(lm_RMSE_sqrt, simple_rmse_sqrt, ridge_RMSE, lasso_RMSE),
`Test RMSE` =
c(lm_RMSE, simple_rmse, ridge_RMSE_fix, lasso_RMSE_fix)) %>%
write_tsv("results/model-evaluation-regression.tsv")
##################### Tree-based methods ######################################
# evaluate tree RMSE
tree_pred_sqrt = predict(optimal_tree, newdata = school_test)
tree_rmse_sqrt = sqrt(
mean((tree_pred_sqrt-school_test$crimes_per1000_sqrt)^2))
tree_RMSE = sqrt(
mean((tree_pred_sqrt^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate Random Forest RMSE
rf_predictions = predict(rf_fit_tuned, newdata = school_test)
rf_RMSE_sqrt = sqrt(mean((rf_predictions-school_test$crimes_per1000_sqrt)^2))
rf_RMSE = sqrt(mean((rf_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate Boosting RMSE
# n.trees = 242 comes from files 5-tree-modeling, line 201
gbm_predictions = predict(gbm_fit_tuned, n.trees = 242,
newdata = school_test)
gbm_RMSE_sqrt = sqrt(mean((gbm_predictions-school_test$crimes_per1000_sqrt)^2))
gbm_RMSE = sqrt(mean((gbm_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
tibble(Method = c("Regression Tree", "Random Forest", "Boosting"),
`Test RMSE (Sqrt Transformed)` =
c(tree_rmse_sqrt, rf_RMSE_sqrt, gbm_RMSE_sqrt),
`Test RMSE` = c(tree_RMSE, rf_RMSE, gbm_RMSE)) %>%
write_tsv("results/model-evaluation-tree.tsv")
################# General Evaluation ########################################
tibble(Method =
c("OLS", "Intercept-Only", "Ridge", "Lasso",
"Tree", "Random Forest", "Boosting"),
`Test RMSE` = c(lm_RMSE, simple_rmse, ridge_RMSE_fix, lasso_RMSE_fix,
tree_RMSE, rf_RMSE, gbm_RMSE)) %>%
write_tsv("results/model-evaluation-total.tsv")
rf_fit_tuned = randomForest(crimes_per1000_sqrt ~ .,
importance = TRUE,
ntree = 500,
mtry = 11,
data = school_train1)
save(rf_fit_tuned, file = "results/rf_fit_tuned.Rda")
opt_num_trees
optimal_trees
# load libraries
library(glmnetUtils)
library(tidyverse)
# load test data
school_test = read_tsv("data/clean/school_test.tsv") %>%
mutate(across(c("urban_centric_locale", "school_type", "charter"),
factor)) %>%
select(-c(ncessch, year, county_code)) %>%
filter(crimes_per1000 < max(crimes_per1000)) %>%
mutate(crimes_per1000_sqrt = sqrt(crimes_per1000)) %>%
select(-c(crimes_per1000))
# load all models
load("results/ridge_fit.Rda")
load("results/lasso_fit.Rda")
load("results/elnet_fit.Rda")
load("results/optimal_tree.Rda")
load("results/rf_fit_tuned.Rda")
load("results/gbm_fit_tuned.Rda")
########################### Regression-Based Methods ###########################
# for benchmark, find RMSE when just predicting the mean of the training set
simple_pred = mean(school_train$crimes_per1000_sqrt)
simple_rmse_sqrt = sqrt(
mean((simple_pred-(school_test$crimes_per1000_sqrt))^2))
simple_rmse = sqrt(
mean((simple_pred^2-(school_test$crimes_per1000_sqrt)^2)^2))
lm_RMSE_sqrt = sqrt(
mean((lm_predictions-(school_test$crimes_per1000_sqrt))^2))
lm_RMSE = sqrt(
mean((lm_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate OLS RMSE
lm_predictions = predict(lm_fit, newdata = school_test)
lm_RMSE_sqrt = sqrt(
mean((lm_predictions-(school_test$crimes_per1000_sqrt))^2))
lm_RMSE = sqrt(
mean((lm_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate ridge RMSE
ridge_predictions = predict(ridge_fit,
newdata = school_test,
s = "lambda.1se") %>% as.numeric()
ridge_pred_train = predict(ridge_fit,
newdata = school_train,
s = "lambda.1se") %>% as.numeric()
ridge_RMSE = sqrt(
mean((ridge_predictions-(school_test$crimes_per1000_sqrt))^2))
ridge_RMSE_fix = sqrt(
mean((ridge_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
school_train %>%
ggplot(aes(x = crimes_per1000_sqrt, y = ridge_pred_train)) +
geom_point() +
geom_abline(slope = 1)
# evaluate lasso RMSE
lasso_predictions = predict(lasso_fit,
newdata = school_test,
s = "lambda.1se") %>% as.numeric()
lasso_RMSE = sqrt(
mean((lasso_predictions-(school_test$crimes_per1000_sqrt))^2))
lasso_RMSE_fix = sqrt(
mean((lasso_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate elnet RMSE
#elnet_predictions = predict(elnet_fit,
#alpha = extract_best_elnet(elnet_fit)$alpha,
#newdata = school_test,
#s = "lambda.1se") %>% as.numeric()
#elnet_rmse = sqrt(mean((elnet_predictions - school_test$crimes_per1000_sqrt)^2))
#elnet_rmse_fix = sqrt(
#mean((elnet_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# Summary of regression methods
tibble(Method = c("OLS", "Intercept-Only", "Ridge", "Lasso"),
`Test RMSE (Sqrt Transformed)` =
c(lm_RMSE_sqrt, simple_rmse_sqrt, ridge_RMSE, lasso_RMSE),
`Test RMSE` =
c(lm_RMSE, simple_rmse, ridge_RMSE_fix, lasso_RMSE_fix)) %>%
write_tsv("results/model-evaluation-regression.tsv")
##################### Tree-based methods ######################################
# evaluate tree RMSE
tree_pred_sqrt = predict(optimal_tree, newdata = school_test)
tree_rmse_sqrt = sqrt(
mean((tree_pred_sqrt-school_test$crimes_per1000_sqrt)^2))
tree_RMSE = sqrt(
mean((tree_pred_sqrt^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate Random Forest RMSE
rf_predictions = predict(rf_fit_tuned, newdata = school_test)
rf_RMSE_sqrt = sqrt(mean((rf_predictions-school_test$crimes_per1000_sqrt)^2))
rf_RMSE = sqrt(mean((rf_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
# evaluate Boosting RMSE
# n.trees = 242 comes from files 5-tree-modeling, line 188
gbm_predictions = predict(gbm_fit_tuned, n.trees = 518,
newdata = school_test)
gbm_RMSE_sqrt = sqrt(mean((gbm_predictions-school_test$crimes_per1000_sqrt)^2))
gbm_RMSE = sqrt(mean((gbm_predictions^2-(school_test$crimes_per1000_sqrt)^2)^2))
tibble(Method = c("Regression Tree", "Random Forest", "Boosting"),
`Test RMSE (Sqrt Transformed)` =
c(tree_rmse_sqrt, rf_RMSE_sqrt, gbm_RMSE_sqrt),
`Test RMSE` = c(tree_RMSE, rf_RMSE, gbm_RMSE)) %>%
write_tsv("results/model-evaluation-tree.tsv")
################# General Evaluation ########################################
tibble(Method =
c("OLS", "Intercept-Only", "Ridge", "Lasso",
"Tree", "Random Forest", "Boosting"),
`Test RMSE` = c(lm_RMSE, simple_rmse, ridge_RMSE_fix, lasso_RMSE_fix,
tree_RMSE, rf_RMSE, gbm_RMSE)) %>%
write_tsv("results/model-evaluation-total.tsv")
options(scipen = 0, digits = 3)  # controls number of significant digits printed
library(tidyverse)
library(kableExtra)
knitr::include_graphics("../results/response-hist-whole.png")
knitr::include_graphics("../results/response-hist-trans.png")
read_tsv("../results/top-10-schools-data.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("School", "Crimes per 1000 Students"),
caption = "Top ten schools by crime rate
(expressed as per 1000 students).") %>%
kable_styling(position = "center")
read_tsv("../results/top-10-schools-data.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("School", "Crimes per 1000 Students"),
caption = "Top ten schools by crime rate
(expressed as per 1000 students).") %>%
kable_styling(position = "center", latex_options = "HOLD_position")
knitr::include_graphics("../results/school-corrplot.png")
#knitr::include_graphics("../results/county-corrplot.png")
knitr::include_graphics("../results/county-school-corrplot.png")
knitr::include_graphics("../results/county-corrplot.png")
knitr::include_graphics(c("../results/crime_vs_poverty.png","../results/crime_vs_unemployment.png", "../results/Crimes_vs_threats.png"))
setwd("C:/Users/mark/OneDrive/STAT 471/stat-final-proj")
knitr::include_graphics(c("../results/crime_vs_poverty.png","../results/crime_vs_unemployment.png", "../results/Crimes_vs_threats.png"))
knitr::include_graphics(c("../results/crime_vs_unemployment.png", "../results/Crimes_vs_threats.png"))
knitr::include_graphics("../results/crime_vs_poverty.png")
knitr::include_graphics(c("../results/crime_vs_poverty.png","../results/crime_vs_poverty.png"))
knitr::include_graphics(c("../results/crime_vs_poverty.png","../results/crime_vs_unemployment.png","../results/Crimes_vs_threats.png"))
knitr::include_graphics(c("../results/crime_vs_poverty.png","../results/crime_vs_unemployment.png"))
knitr::include_graphics(c("../results/crime_vs_poverty.png","../results/crime_vs_unemployment.png"))
knitr::include_graphics(c("../results/crime_vs_poverty.png"))
knitr::include_graphics(c("../results/crime_vs_poverty.png", "../results/crime_vs_unemployment.png"))
p1 <- ggdraw() + draw_image("../results/crime_vs_poverty.png", scale = 0.9)
p2 <- ggdraw() + draw_image("../results/crime_vs_unemployment.png", scale = 0.9)
plot_grid(p1, p2)
p1
library(cowplot)
library(ggplot2)
library(cowplot)
library(ggplot2)
p1 <- ggdraw() + draw_image("../results/crime_vs_poverty.png", scale = 0.9)
p2 <- ggdraw() + draw_image("../results/crime_vs_unemployment.png", scale = 0.9)
plot_grid(p1, p2)
install.packages("magick")
#install.packages("magick")
#library(cowplot)
#library(ggplot2)
p1 <- ggdraw() + draw_image("../results/crime_vs_poverty.png", scale = 0.9)
p2 <- ggdraw() + draw_image("../results/crime_vs_unemployment.png", scale = 0.9)
knitr::include_graphics("../results/crime_vs_poverty.png")
```{r scatterplots1, out.width = "50%", fig.cap = "School-Specific and County-Level Features Correlation Plot", fig.align='center', echo = FALSE, fig.pos = "H"}
knitr::include_graphics("../results/crime_vs_poverty.png")
knitr::include_graphics("../results/crime_vs_poverty.png")
knitr::include_graphics("../results/crime_vs_unemployment.png")
knitr::include_graphics("../results/crime_vs_unemployment.png")
knitr::scatterplots3("../results/Crimes_vs_threats.png")
knitr::scatterplots3("../results/Crimes_vs_threats.png")
knitr::include_graphics("../results/crime_vs_poverty.png")
knitr::include_graphics("../results/crime_vs_poverty.png")
knitr::include_graphics("../results/crime_vs_poverty.png")
knitr::include_graphics("../results/crime_vs_unemployemnt.png)
knitr::include_graphics("../results/crime_vs_unemployemnt.png")
knitr::scatterplots3("../results/Crimes_vs_threats.png")
knitr::include_graphics("../results/Crimes_vs_threats.png")
knitr::include_graphics("../results/crimes_vs_schooltype.png")
knitr::include_graphics("../results/coverpage.jpg")
knitr::include_graphics("../results/coverpage.jpg")
knitr::include_graphics("../results/coverpage.jpg")
summary(lm_fit)
knitr::include_graphics("../results/OLS summary.JPG")
knitr::include_graphics("../results/lasso-cv-plot.png")
knitr::include_graphics("../results/lasso-trace-plot.png")
read_tsv("../results/lasso-features-table.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Feature", "Coefficient"),
caption = "Standardized coefficients for features in the lasso
model based on the one-standard-error rule.") %>%
kable_styling(position = "center")
read_tsv("../results/model-evaluation-regression.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "RMSE (Log)", "RMSE"),
caption = "RMSE summary for Regression based methods") %>%
kable_styling(position = "center")
read_tsv("../results/model-evaluation-tree.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "RMSE (Log)", "RMSE"),
caption = "RMSE summary for Tree based methods") %>%
kable_styling(position = "center")
read_tsv("../results/model-evaluation-total.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "RMSE"),
caption = "RMSE summary for all data minig methods used") %>%
kable_styling(position = "center")
knitr::include_graphics("../results/ridgefit_cv.png")
knitr::include_graphics("../results/lasso-cv-plot.JPG")
knitr::include_graphics("../results/lasso-cv-plot.png")
knitr::include_graphics("../results/ridgefit_cv.png")
knitr::include_graphics("../results/lasso-cv-plot.png")
rpart.plot(optimal_tree)
rpart.plot(optimal_tree)
knitr::include_graphics("../results/results/treenodes_cv_error.png")
knitr::include_graphics("..results/treenodes_cv_error.png")
knitr::include_graphics("../results/treenodes_cv_error.png")
knitr::include_graphics("../results/optimaltree.png")
knitr::include_graphics("../results/rf_numtree.png")
knitr::include_graphics("../results/rf_numtrees.png")
knitr::include_graphics("../results/rf_numtrees.png")
knitr::include_graphics("../results/m_oob.png")
knitr::include_graphics("../results/rf_variable_importance.png")
knitr::include_graphics("../results/interaction_depth_tuning.png")
read_tsv("../results/top-10-features-boosting.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Feature", "Coefficient"),
caption = "Boosting top 10 most important features based on purity score") %>%
kable_styling(position = "center", latex_options = "HOLD_position")
knitr::include_graphics("../results/salaries_dependence.png")
knitr::include_graphics("../results/threats_dependence.png")
knitr::include_graphics("../results/suspension_dependence.png")
read_tsv("../results/model-evaluation-total.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "RMSE"),
caption = "RMSE summary for all data minig methods used") %>%
kable_styling(position = "center")
read_tsv("../results/model-evaluation-tree.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "RMSE (Log)", "RMSE"),
caption = "RMSE summary for Tree based methods") %>%
kable_styling(position = "center", latex_options = "HOLD_position")
read_tsv("../results/model-evaluation-regression.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "RMSE"),
caption = "RMSE summary for regression methods") %>%
kable_styling(position = "center", latex_options = "HOLD_position")
read_tsv("../results/model-evaluation-regression.tsv")
read_tsv("../results/model-evaluation-regression.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "Test RMSE (transformed), Test RMSE"),
caption = "RMSE summary for regression methods") %>%
kable_styling(position = "center", latex_options = "HOLD_position")
read_tsv("../results/model-evaluation-regression.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "Test RMSE (transformed)", "Test RMSE"),
caption = "RMSE summary for regression methods") %>%
kable_styling(position = "center", latex_options = "HOLD_position")
read_tsv("../results/model-evaluation-total.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "RMSE"),
caption = "RMSE summary for all data minig methods used") %>%
kable_styling(position = "center", latex_options = "HOLD_position")
read_tsv("../results/model-evaluation-total.tsv")
read_tsv("../results/model-evaluation-total.tsv") %>%
kable(format = "latex", row.names = NA,
booktabs = TRUE, digits = 2,
col.names = c("Method", "RMSE"),
caption = "RMSE summary for all data minig methods used") %>%
kable_styling(position = "center", latex_options = "HOLD_position")
str(joined)
joined$Poverty_all_population
joined$Household_income
